<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Fluent-bit日志插件配置说明</title>
      <link href="/2020/03/06/fluent-bit-ri-zhi-cha-jian-pei-zhi-shuo-ming/"/>
      <url>/2020/03/06/fluent-bit-ri-zhi-cha-jian-pei-zhi-shuo-ming/</url>
      
        <content type="html"><![CDATA[<h1 id="Fluent-bit日志插件配置说明"><a href="#Fluent-bit日志插件配置说明" class="headerlink" title="Fluent-bit日志插件配置说明"></a>Fluent-bit日志插件配置说明</h1><h3 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h3><p>fluent-bit配置文件中，主要由输入（Input）、解析器（Parser）、过滤器（Filter）、缓存（Buffer）、路由（Routing）、输出（Output）六大模块组成，各个模块的详细说明如下：</p><p><img src="/medias/logging_pipeline.png" alt="fluent-bit数据流图"></p><table><thead><tr><th>Interface</th><th>Description(英文)</th><th>Description(中文)</th></tr></thead><tbody><tr><td>Input</td><td>Entry point of data. Implemented through Input Plugins, this interface allows to gather or receive data. E.g: log file content, data over TCP, built-in metrics, etc.</td><td>数据的入口点。通过输入插件实现，此接口允许收集或接收数据。例如：日志文件内容，TCP上的数据，内置指标等。</td></tr><tr><td>Parser</td><td>Parsers allow to convert unstructured data gathered from the Input interface into a structured one. Parsers are optional and depends on Input plugins.</td><td>解析器允许将从Input接口收集的非结构化数据转换为结构化数据。解析器是可选的，并且取决于Input插件。</td></tr><tr><td>Filter</td><td>The filtering mechanism allows to alter the data ingested by the Input plugins. Filters are implemented as plugins.</td><td>过滤机制允许更改 Input插件提取的数据。过滤器被实现为插件。</td></tr><tr><td>Buffer</td><td>By default, the data ingested by the Input plugins, resides in memory until is routed and delivered to an Output interface.</td><td>默认情况下，Input插件提取的数据将驻留在内存中，直到路由并传递到Output接口为止。</td></tr><tr><td>Routing</td><td>Data ingested by an Input interface is tagged, that means that a Tag is assigned and this one is used to determinate where the data should be routed based on a match rule.</td><td>Input接口摄取的数据被标记，这意味着分配了一个Tag，并且该标记用于根据匹配规则确定应将数据路由到的位置。</td></tr><tr><td>Output</td><td>An output defines a destination for the data. Destinations are handled by output plugins. Note that thanks to the Routing interface, the data can be delivered to multiple destinations.</td><td>输出定义数据的目的地。目的地由输出插件处理。请注意，借助“路由”接口，可以将数据传递到多个目的地。</td></tr></tbody></table><h3 id="二、配置文件"><a href="#二、配置文件" class="headerlink" title="二、配置文件"></a>二、配置文件</h3><p>一个fluent-bit配置文件除了包括输入（Input）、解析器（Parser）、过滤器（Filter）、缓存（Buffer）、路由（Routing）、输出（Output）六个模块外，还需要配置Service，该模块主要负责fluent-bit的配置，如Parser配置文件路径、fluent-bit自身日志打印等。如下是fluent-bit.conf配置：</p><pre><code>[SERVICE]    Flush        1    Daemon       Off    Log_Level    debug    Parsers_File parsers.conf[INPUT]    Name             tail    Path             ${K8S_LOG_DIR}/*.log    Parser           json    Tag              kube_file.*    Refresh_Interval 5    Mem_Buf_Limit    5MB    Skip_Long_Lines  OFF[FILTER]    Name             record_modifier    Match            kube_file.*    Record           hostname ${K8S_HOSTNAME}    Record           namespace ${K8S_POD_NAMESPACE}    Record           application ${K8S_APPLICATION_NAME}    Record           pod ${K8S_POD_NAME}    Record           container ${K8S_CONTAINER_NAME}    Record           node ${K8S_NODE_NAME}[OUTPUT]    Name             es    Match            *    Host             ${ELASTICSEARCH_HOST}    Port             ${ELASTICSEARCH_PORT}    Logstash_Format  On    Retry_Limit      False    Type             flb_type    Time_Key         time    Time_Key_Format  yyyy-MM-dd HH:mm:ss.SSS    Replace_Dots     On    Logstash_Prefix  segma_application_file</code></pre><h3 id="三、Service"><a href="#三、Service" class="headerlink" title="三、Service"></a>三、Service</h3><p>Service各个配置项如下：<br>|Key|Description|中文描述|Default Value|<br>|-|-|-|-|<br>|Flush| Set the flush time in seconds. Everytime it timeouts, the engine will flush the records to the output plugin. | 设置Flush时间（以秒为单位）。每次超时，引擎都会将记录刷新到输出插件。| 5|<br>|Daemon|Boolean value to set if Fluent Bit should run as a Daemon (background) or not. Allowed values are: yes, no, on and off.    |一个布尔值，用于设置Fluent Bit是否应作为守护程序（后台）运行。允许的值为：是，否，打开和关闭。|Off|<br>|Log_File    |Absolute path for an optional log file.|可选日志文件的绝对路径。|    |<br>|Log_Level|    Set the logging verbosity level. Allowed values are: error, info, debug and trace. Values are accumulative, e.g: if ‘debug’ is set, it will include error, info and debug. Note that trace mode is only available if Fluent Bit was built with the WITH_TRACE option enabled.    |设置日志记录的详细程度。允许的值为：error, info, debug 和 trace。值是累积值，例如：如果设置了“ debug”，则它将包括error, info 和 debug。请注意，只有在启用WITH_TRACE选项的情况下构建Fluent Bit时，跟踪模式才可用。|info|<br>|Parsers_File    |Path for a parsers configuration file. Multiple Parsers_File entries can be used.    |配置文件的路径。可以使用多个Parsers_File条目。 |<br>|HTTP_Server|    Enable built-in HTTP Server    |启用内置的HTTP服务器|Off|<br>|HTTP_Listen|    Set listening interface for HTTP Server when it’s enabled|启用HTTP Server时设置监听接口    |0.0.0.0|<br>|HTTP_Port|    Set TCP Port for the HTTP Server|设置HTTP服务器的TCP端口|    2020|</p><p>在Kubernetes中进行日志收集时，一般需要配置的项有：Flush、Daemon、Log_Level、Parsers_File。在调试插件时，关闭Daemon以及设置Log_Level为debug甚至更高可方便查看插件运行错误。Parsers_File对应解析器的配置，可参考官方提供的<a href="https://raw.githubusercontent.com/fluent/fluent-bit/master/conf/parsers.conf" target="_blank" rel="noopener">parsers.conf</a></p><h3 id="四、Input"><a href="#四、Input" class="headerlink" title="四、Input"></a>四、Input</h3><p>INPUT模块指点了日志输入源，每个输入插件都可以添加自己的配置键。以下为目前官方支持的输入源插件,<a href="https://fluentbit.io/documentation/0.13/input/" target="_blank" rel="noopener">官方Input Plugins</a>。运行在kubernetes集群内的应用日志收集时，我们使用的是tail插件常用参数如下：</p><table><thead><tr><th>Key</th><th>Description</th><th>中文描述</th><th>Default</th></tr></thead><tbody><tr><td>Buffer_Chunk_Size</td><td>Set the initial buffer size to read files data. This value is used too to increase buffer size. The value must be according to the Unit Size specification.</td><td>设置初始缓冲区大小以读取文件数据。该值也用于增加缓冲区大小。该值必须符合“ 单位大小”规范。</td><td>32k</td></tr><tr><td>Buffer_Max_Size</td><td>Set the limit of the buffer size per monitored file. When a buffer needs to be increased (e.g: very long lines), this value is used to restrict how much the memory buffer can grow. If reading a file exceed this limit, the file is removed from the monitored file list. The value must be according to the Unit Size specification.</td><td>设置每个受监视文件的缓冲区大小的限制。当需要增加缓冲区时（例如：很长的行），该值用于限制内存缓冲区可以增长多少。如果读取的文件超过此限制，将从监视的文件列表中删除该文件。该值必须符合“ 单位大小”规范。</td><td>Buffer_Chunk_Size</td></tr><tr><td>Path</td><td>Pattern specifying a specific log files or multiple ones through the use of common wildcards.</td><td>通过使用通用通配符指定一个或多个特定日志文件的模式。</td><td></td></tr><tr><td>Path_Key</td><td>If enabled, it appends the name of the monitored file as part of the record. The value assigned becomes the key in the map.</td><td>如果启用，它将附加受监视文件的名称作为记录的一部分。分配的值成为映射中的键。</td><td></td></tr><tr><td>Exclude_Path</td><td>Set one or multiple shell patterns separated by commas to exclude files matching a certain criteria, e.g: exclude_path=<em>.gz,</em>.zip</td><td>设置一个或多个用逗号分隔的外壳模式，以排除符合特定条件的文件，例如：exclude_path = <em>.gz，</em>.zip</td><td></td></tr><tr><td>Refresh_Interval</td><td>The interval of refreshing the list of watched files. Default is 60 seconds.</td><td>刷新监视文件列表的时间间隔。默认值为60秒。</td><td></td></tr><tr><td>Rotate_Wait</td><td>Specify the number of extra seconds to monitor a file once is rotated in case some pending data is flushed. Default is 5 seconds.</td><td>指定在刷新某些未决数据时旋转一次后监视文件的额外秒数。默认值为5秒。</td><td></td></tr><tr><td>Skip_Long_Lines</td><td>When a monitored file reach it buffer capacity due to a very long line (Buffer_Max_Size), the default behavior is to stop monitoring that file. Skip_Long_Lines alter that behavior and instruct Fluent Bit to skip long lines and continue processing other lines that fits into the buffer size.</td><td>当受监视的文件由于行很长（Buffer_Max_Size）而达到缓冲区容量时，默认行为是停止监视该文件。Skip_Long_Lines会更改该行为，并指示Fluent Bit跳过长行并继续处理适合缓冲区大小的其他行。</td><td>Off</td></tr><tr><td>DB</td><td>Specify the database file to keep track of monitored files and offsets.</td><td>指定数据库文件以跟踪受监视的文件和偏移量。</td><td></td></tr><tr><td>DB.Sync</td><td>Set a default synchronization (I/O) method. Values: Extra, Full, Normal, Off. This flag affects how the internal SQLite engine do synchronization to disk, for more details about each option please refer to this section.</td><td>设置默认的同步（I / O）方法。值：Extra，Full，Normal，Off。此标志影响内部SQLite引擎与磁盘同步的方式，有关每个选项的更多详细信息，请参阅本节。</td><td>Full</td></tr><tr><td>Mem_Buf_Limit</td><td>Set a limit of memory that Tail plugin can use when appending data to the Engine. If the limit is reach, it will be paused; when the data is flushed it resumes.</td><td>设置将数据附加到引擎时，Tail插件可以使用的内存限制。如果达到极限，它将被暂停；刷新数据后，它将恢复。</td><td></td></tr><tr><td>Parser</td><td>Specify the name of a parser to interpret the entry as a structured message.</td><td>指定解析器的名称，以将条目解释为结构化消息。</td><td></td></tr><tr><td>Key</td><td>When a message is unstructured (no parser applied), it’s appended as a string under the key name log. This option allows to define an alternative name for that key.</td><td>当消息是非结构化消息（未应用解析器）时，它将作为字符串附加在键名log下。此选项允许为该键定义替代名称。</td><td>log</td></tr></tbody></table><p>常用的参数有Path、Parser、Tag、Refresh_Interval、Mem_Buf_Limit、Skip_Long_Lines。Path指定日志所在目录；Tag为Routing参数，会在Routing章节介绍；Refresh_Interval指定日志刷新时间间隔，会直接影响日志收集的实时性，一般设置为5秒；Mem_Buf_Limit指定插件内存大小，一般设置5Mb;Skip_Long_Lines一般使用默认值Off；其中比较重要的是Parser参数的配置，主要匹配Parser解析器，其值为解析器的name值，下一章介绍Parser解析器。</p><h3 id="五、Parser"><a href="#五、Parser" class="headerlink" title="五、Parser"></a>五、Parser</h3><p>Parser解析器的配置是单独的一个配置文件，配置的加载是由Service模块的Parsers_File参数指定。可参考官方提供的<a href="https://raw.githubusercontent.com/fluent/fluent-bit/master/conf/parsers.conf" target="_blank" rel="noopener">parsers.conf</a></p><h3 id="六、Filter"><a href="#六、Filter" class="headerlink" title="六、Filter"></a>六、Filter</h3><p>Filter插件允许改变输入数据的结构，例如在Kubernetes集群中，我们需要日志记录应用的名字以及所在节点，而默认日志未打印该值，我们便可以使用Filter附加该值。详情见<a href="https://fluentbit.io/documentation/0.13/filter/" target="_blank" rel="noopener">官方插件</a>信息</p><h3 id="七、Buffer"><a href="#七、Buffer" class="headerlink" title="七、Buffer"></a>七、Buffer</h3><p>当准备好将数据或日志路由到某个目标位置时，默认情况下会将它们缓冲在内存中。</p><h3 id="八、Routing"><a href="#八、Routing" class="headerlink" title="八、Routing"></a>八、Routing</h3><p>路由是一项核心功能，可让您通过过滤器将数据路由到一个或多个目的地。路由主要由两个参数控制。</p><ul><li>Tag：当数据由输入插件生成时，它附带一个标签（大多数情况下是手动配置该标签），该标签是人类可读的指示器，有助于识别数据源。</li><li>Match：我们定义其中的数据应被路由，一个匹配规则在配置中进行分配。</li></ul><p>下面文件将简单介绍路由规则的实现：</p><pre><code>[INPUT]    Name cpu    Tag  my_cpu[INPUT]    Name mem    Tag  my_mem[OUTPUT]    Name   es    Match  my_cpu[OUTPUT]    Name   stdout    Match  my_mem</code></pre><p>在上面的配置中，es输出通过Match值my_cpu匹配到输入插件cpu的Tag值，而stdout输出则通过Match值my_mem匹配到输入插件mem的Tag值，所以es输出只接收cpu输出，stdout输出只接收mem输出。</p><h3 id="九、Output"><a href="#九、Output" class="headerlink" title="九、Output"></a>九、Output</h3><p>输出接口允许定义数据的目的地。通用目标是远程服务，本地文件系统或其他标准接口。输出实现为插件，并且有很多可用的插件。<br>有关更多详细信息，请参阅“<a href="https://fluentbit.io/documentation/0.13/output/" target="_blank" rel="noopener">输出插件</a>”部分。</p><p>Filter</p><h3 id="附录-Fluent-bit官方文档"><a href="#附录-Fluent-bit官方文档" class="headerlink" title="附录 Fluent-bit官方文档"></a>附录 Fluent-bit官方文档</h3><p><a href="https://fluentbit.io/documentation/0.13/configuration/file.html" target="_blank" rel="noopener">https://fluentbit.io/documentation</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FTP服务器搭建</title>
      <link href="/2020/02/19/ftp-fu-wu-qi-da-jian/"/>
      <url>/2020/02/19/ftp-fu-wu-qi-da-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="FTP服务搭建"><a href="#FTP服务搭建" class="headerlink" title="FTP服务搭建"></a>FTP服务搭建</h1><ul><li>系统： centos 7.4</li></ul><h3 id="一、安装vsftpd"><a href="#一、安装vsftpd" class="headerlink" title="一、安装vsftpd"></a>一、安装vsftpd</h3><pre class=" language-sh"><code class="language-sh">yum -y install vsftpd</code></pre><h3 id="二、配置服务"><a href="#二、配置服务" class="headerlink" title="二、配置服务"></a>二、配置服务</h3><pre class=" language-sh"><code class="language-sh">[root@ecs-7fd0 vsftpd]# cat /etc/vsftpd/vsftpd.confanonymous_enable=NOlocal_enable=YESwrite_enable=YESlocal_umask=022dirmessage_enable=YESxferlog_enable=YESxferlog_std_format=YESascii_upload_enable=YESascii_download_enable=YESchroot_local_user=YESlisten=NOlisten_ipv6=YESconnect_from_port_20=NO#设置使用主动模式pasv_enable=YESpasv_min_port=1024pasv_max_port=65536pam_service_name=vsftpdguest_enable=YES#设置使用虚拟用户的真实访问用户guest_username=ftpuseruser_config_dir=/etc/vsftpd/vsftpd_user_confallow_writeable_chroot=YES#设置使用虚拟用户virtual_use_local_privs=YESuserlist_enable=YESuserlist_deny=NOtcp_wrappers=YES</code></pre><h3 id="三、创建ftpuser账户"><a href="#三、创建ftpuser账户" class="headerlink" title="三、创建ftpuser账户"></a>三、创建ftpuser账户</h3><pre class=" language-sh"><code class="language-sh">useradd -d /home/ftpuser -s /sbin/nologin ftpuser</code></pre><h3 id="三、虚拟用户"><a href="#三、虚拟用户" class="headerlink" title="三、虚拟用户"></a>三、虚拟用户</h3><ul><li>设置pam策略</li></ul><pre class=" language-sh"><code class="language-sh">[root@ecs-7fd0 vsftpd]# cat /etc/pam.d/vsftpd#%PAM-1.0#session    optional     pam_keyinit.so    force revoke#auth       required    pam_listfile.so item=user sense=deny file=/etc/vsftpd/ftpusers onerr=succeed#auth       required    pam_shells.so#auth       include    password-auth#account    include    password-auth#session    required     pam_loginuid.so#session    include    password-authauth       required    pam_userdb.so   db=/etc/vsftpd/vsftpd_loginaccount    required    pam_userdb.so   db=/etc/vsftpd/vsftpd_login</code></pre><ul><li>配置虚拟账户</li></ul><pre class=" language-sh"><code class="language-sh">[root@ecs-7fd0 vsftpd]# cat ftp_virtual_user User001PasswordForUser001User002PasswordForUser002User003PasswordForUser003</code></pre><ul><li>生成虚拟账号数据库</li></ul><pre class=" language-sh"><code class="language-sh">[root@ecs-7fd0 vsftpd]# db_load -T -t hash -f /etc/vsftpd/ftp_virtual_user /etc/vsftpd/vsftpd_login.db</code></pre><ul><li>配置虚拟账户访问目录</li></ul><pre class=" language-sh"><code class="language-sh">[root@ecs-7fd0 vsftpd]# mkdir -p /etc/vsftpd/vsftpd_user_conf[root@ecs-7fd0 vsftpd]# cat User001local_root=/home/ftpuser/User001write_enable=YESanon_world_readable_only=YESanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES[root@ecs-7fd0 vsftpd]# cat User002local_root=/home/ftpuser/User002write_enable=YESanon_world_readable_only=YESanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES[root@ecs-7fd0 vsftpd]# cat User003local_root=/home/ftpuser/User003write_enable=YESanon_world_readable_only=YESanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES</code></pre><ul><li>启动vsftpd</li></ul><pre class=" language-sh"><code class="language-sh">[root@ecs-7fd0 vsftpd]# systemctl enable vsftpd[root@ecs-7fd0 vsftpd]# systemctl start vsftpd</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> FTP </tag>
            
            <tag> 共享存储 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph集群安装</title>
      <link href="/2020/02/14/ceph-ji-qun-an-zhuang/"/>
      <url>/2020/02/14/ceph-ji-qun-an-zhuang/</url>
      
        <content type="html"><![CDATA[<h1 id="CephFS集群安装"><a href="#CephFS集群安装" class="headerlink" title="CephFS集群安装"></a>CephFS集群安装</h1><h3 id="一、集群规划"><a href="#一、集群规划" class="headerlink" title="一、集群规划"></a>一、集群规划</h3><table><thead><tr><th>节点</th><th>ip</th><th>os</th><th>节点说明</th></tr></thead><tbody><tr><td>master1</td><td>10.73.13.61</td><td>centos7.4</td><td>mon+rgw+manger节点、ceph-deploy</td></tr><tr><td>master2</td><td>10.73.13.60</td><td>centos7.4</td><td>mon+rgw+manger节点</td></tr><tr><td>master3</td><td>10.73.13.59</td><td>centos7.4</td><td>mon+rgw+manger节点</td></tr></tbody></table><h3 id="二、安装ceph-deploy"><a href="#二、安装ceph-deploy" class="headerlink" title="二、安装ceph-deploy"></a>二、安装ceph-deploy</h3><ol><li>Install and enable the Extra Packages for Enterprise Linux (EPEL) repository:Install and enable the Extra Packages for Enterprise Linux (EPEL) repository:</li></ol><pre class=" language-sh"><code class="language-sh">sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</code></pre><ol start="2"><li>添加ceph仓库（阿里源，同时在所有节点进行如下操作）</li></ol><pre class=" language-sh"><code class="language-sh">cat << EOM > /etc/yum.repos.d/ceph.repo[Ceph]name=Ceph packages for $basearchbaseurl=https://mirrors.aliyun.com/ceph/rpm-mimic/el7/$basearchenabled=1gpgcheck=1type=rpm-mdgpgkey=https://download.ceph.com/keys/release.ascpriority=1[Ceph-noarch]name=Ceph noarch packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-mimic/el7/noarchenabled=1gpgcheck=1type=rpm-mdgpgkey=https://download.ceph.com/keys/release.ascpriority=1[ceph-source]name=Ceph source packagesbaseurl=https://mirrors.aliyun.com/ceph/rpm-mimic/el7/SRPMSenabled=1EOM</code></pre><ol start="3"><li>安装python-setuptools、ceph-deploy</li></ol><pre class=" language-sh"><code class="language-sh">sudo yum install python-setuptoolssudo yum install ceph-deploy</code></pre><h3 id="三、节点准备"><a href="#三、节点准备" class="headerlink" title="三、节点准备"></a>三、节点准备</h3><p>以下操作需在所有节点进行。</p><ol><li>免密登录</li></ol><pre class=" language-sh"><code class="language-sh"># 1、三次回车后，密钥生成完成ssh-keygen# 2、拷贝密钥到其他节点ssh-copy-id -i ~/.ssh/id_rsa.pub  用户名字@192.168.x.xxx</code></pre><ol start="2"><li>时间同步</li></ol><p>网上教程很多，具体可参考网上文档。</p><pre class=" language-sh"><code class="language-sh">sudo yum install ntpdatentpdate -u ntp.api.bz</code></pre><ol start="3"><li>关闭SELinux、防火墙</li></ol><pre class=" language-sh"><code class="language-sh">systemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config</code></pre><ol start="4"><li>关闭系统的Swap（Kubernetes 1.8开始要求）</li></ol><pre class=" language-sh"><code class="language-sh">swapoff -ayes | cp /etc/fstab /etc/fstab_bakcat /etc/fstab_bak |grep -v swap > /etc/fstab</code></pre><h3 id="四、集群安装"><a href="#四、集群安装" class="headerlink" title="四、集群安装"></a>四、集群安装</h3><p>以下操作在ceph-deploy节点。</p><ol><li>创建集群</li></ol><pre class=" language-sh"><code class="language-sh">mkdir /etc/ceph && cd /etc/ceph# ceph-deploy new {initial-monitor-node(s)}ceph-deploy new master1 master2 master3 </code></pre><ol start="2"><li>设置集群配置</li></ol><ul><li>具体集群配置说明，待后续更新</li></ul><pre class=" language-sh"><code class="language-sh">cat /etc/ceph/ceph.conf[global]public_network = 10.73.13.0/16cluster_network = 10.73.13.0/16fsid = 464c2aa2-7426-4d6b-a0ae-961d1589ee53mon_initial_members = master1, master2, master3mon_host = 10.73.13.61,10.73.13.60,10.73.13.59auth_cluster_required = cephxauth_service_required = cephxauth_client_required = cephxosd_pool_default_size = 3osd_pool_default_min_size = 1osd_pool_default_pg_num = 8osd_pool_default_pgp_num = 8osd_crush_chooseleaf_type = 1[mon]mon_clock_drift_allowed = 0.5mon allow pool delete = true[osd]osd_mkfs_type = xfsosd_mkfs_options_xfs = -ffilestore_max_sync_interval = 5filestore_min_sync_interval = 0.1filestore_fd_cache_size = 655350filestore_omap_header_cache_size = 655350filestore_fd_cache_random = trueosd op threads = 8osd disk threads = 4filestore op threads = 8max_open_files = 655350[mgr]mgr modules = dashboard</code></pre><ol start="3"><li>为所有节点安装ceph</li></ol><pre class=" language-sh"><code class="language-sh"># ceph-deploy install {initial-monitor-node(s)} --no-adjust-repos# --no-adjust-repos参数的意思是不更新节点配置的ceph源，因为在安装ceph-deploy的步骤下已经为节点配置了阿里云的ceph源ceph-deploy new master1 master2 master3 --no-adjust-repos</code></pre><ol start="4"><li>初始化节点配置,生产相应的keys</li></ol><pre class=" language-sh"><code class="language-sh">ceph-deploy mon create-initial</code></pre><p>完成之后会在/etc/ceph目录下生成以下几个文件</p><pre class=" language-sh"><code class="language-sh">ceph.client.admin.keyringceph.bootstrap-mgr.keyringceph.bootstrap-osd.keyringceph.bootstrap-mds.keyringceph.bootstrap-rgw.keyringceph.bootstrap-rbd.keyringceph.bootstrap-rbd-mirror.keyring</code></pre><ol start="5"><li>拷贝文件至部署节点</li></ol><pre class=" language-sh"><code class="language-sh">ceph-deploy admin master1 master2 master3</code></pre><ol start="6"><li>部署mgr</li></ol><pre class=" language-sh"><code class="language-sh">ceph-deploy mgr create master1 master2 master3</code></pre><ol start="7"><li>添加OSD</li></ol><pre class=" language-sh"><code class="language-sh">ceph-deploy osd create --data /dev/vdb master1ceph-deploy osd create --data /dev/vdb master2ceph-deploy osd create --data /dev/vdb master3</code></pre><h3 id="五、创建CephFS文件系统"><a href="#五、创建CephFS文件系统" class="headerlink" title="五、创建CephFS文件系统"></a>五、创建CephFS文件系统</h3><ol><li>部署metadata服务</li></ol><pre class=" language-sh"><code class="language-sh">ceph-deploy mds create master1 master2 master3</code></pre><ol start="2"><li>生成CephFS</li></ol><pre class=" language-sh"><code class="language-sh">ceph osd pool create cephfs_data 128ceph osd pool create cephfs_meta 128ceph fs new mycephfs cephfs_meta cephfs_data</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ceph </tag>
            
            <tag> 运维 </tag>
            
            <tag> 分布式存储 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kubernetes集群运行问题记录</title>
      <link href="/2020/01/02/kubernetes-ji-qun-yun-xing-wen-ti-ji-lu/"/>
      <url>/2020/01/02/kubernetes-ji-qun-yun-xing-wen-ti-ji-lu/</url>
      
        <content type="html"><![CDATA[<h2 id="kubernetes集群运行问题记录"><a href="#kubernetes集群运行问题记录" class="headerlink" title="kubernetes集群运行问题记录"></a>kubernetes集群运行问题记录</h2><ul><li><p>集群内部容器无法解析外部DNS</p><p>原因：由于节点名为nodex.domain.xx，集群内部容器的/etc/resolv.conf中search域会domain.xx域，容器在解析外网域名时默认会先在外网域名后添加.domain.xx进行域名解析，而外网存在域名domain.xx，且DNS解析域名为<em>.domain.xx，所以会将外网域名解析至</em>.domain.xx对应的IP地址，最终导致容器内部无法访问外网域名。</p><p>解决办法：尽量避免集群内部节点名与外网域名冲突，可采用domain.local结尾等命名方式为节点命名。</p></li><li><p>gitlab迁移之后系统异常</p><p>原因：集群新建gitlab仓库各组件之间的认证文件与原有gialab不一致，导致恢复数据之后部分组件之间交互异常。</p><p>解决办法：新建gitlab之前，迁移原有gitlab中所有的secret文件。</p></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器化 </tag>
            
            <tag> Bugs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes集群安装Cert Manager</title>
      <link href="/2019/12/31/kubernetes-ji-qun-an-zhuang-cert-manager/"/>
      <url>/2019/12/31/kubernetes-ji-qun-an-zhuang-cert-manager/</url>
      
        <content type="html"><![CDATA[<h1 id="安装Cert-Manager"><a href="#安装Cert-Manager" class="headerlink" title="安装Cert Manager"></a>安装Cert Manager</h1><h2 id="一、Installing-the-Chart"><a href="#一、Installing-the-Chart" class="headerlink" title="一、Installing the Chart"></a>一、Installing the Chart</h2><p><a href="https://cert-manager.io/docs/installation/kubernetes/" target="_blank" rel="noopener">https://cert-manager.io/docs/installation/kubernetes/</a></p><h2 id="二、创建ClusterIssuer-集群内所有命名空间公用方案"><a href="#二、创建ClusterIssuer-集群内所有命名空间公用方案" class="headerlink" title="二、创建ClusterIssuer(集群内所有命名空间公用方案)"></a>二、创建ClusterIssuer(集群内所有命名空间公用方案)</h2><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> cert<span class="token punctuation">-</span>manager.io/v1alpha2<span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterIssuer<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> cluster<span class="token punctuation">-</span>letsencrypt<span class="token punctuation">-</span>prod<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">acme</span><span class="token punctuation">:</span>    <span class="token key atrule">email</span><span class="token punctuation">:</span> hnbcao@qq.com    <span class="token key atrule">privateKeySecretRef</span><span class="token punctuation">:</span>      <span class="token key atrule">name</span><span class="token punctuation">:</span> cluster<span class="token punctuation">-</span>letsencrypt<span class="token punctuation">-</span>prod    <span class="token key atrule">server</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//acme<span class="token punctuation">-</span>v02.api.letsencrypt.org/directory    <span class="token key atrule">solvers</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">http01</span><span class="token punctuation">:</span>        <span class="token key atrule">ingress</span><span class="token punctuation">:</span>          <span class="token key atrule">class</span><span class="token punctuation">:</span> traefik</code></pre><h2 id="三、创建Issuer-集群内单个命名空间独享方案"><a href="#三、创建Issuer-集群内单个命名空间独享方案" class="headerlink" title="三、创建Issuer(集群内单个命名空间独享方案)"></a>三、创建Issuer(集群内单个命名空间独享方案)</h2><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> cert<span class="token punctuation">-</span>manager.io/v1alpha2<span class="token key atrule">kind</span><span class="token punctuation">:</span> Issuer<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> letsencrypt<span class="token punctuation">-</span>prod<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">acme</span><span class="token punctuation">:</span>    <span class="token key atrule">email</span><span class="token punctuation">:</span> hnbcao@qq.com    <span class="token key atrule">privateKeySecretRef</span><span class="token punctuation">:</span>      <span class="token key atrule">name</span><span class="token punctuation">:</span> letsencrypt<span class="token punctuation">-</span>prod    <span class="token key atrule">server</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//acme<span class="token punctuation">-</span>v02.api.letsencrypt.org/directory    <span class="token key atrule">solvers</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">http01</span><span class="token punctuation">:</span>        <span class="token key atrule">ingress</span><span class="token punctuation">:</span>          <span class="token key atrule">class</span><span class="token punctuation">:</span> traefik</code></pre><h2 id="四、Ingress应用ClusterIssuer"><a href="#四、Ingress应用ClusterIssuer" class="headerlink" title="四、Ingress应用ClusterIssuer"></a>四、Ingress应用ClusterIssuer</h2><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">kind</span><span class="token punctuation">:</span> Ingress<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> extensions/v1beta1<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> harbor<span class="token punctuation">-</span>ingress  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> ns<span class="token punctuation">-</span>harbor  <span class="token key atrule">labels</span><span class="token punctuation">:</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> harbor    <span class="token key atrule">chart</span><span class="token punctuation">:</span> harbor    <span class="token key atrule">heritage</span><span class="token punctuation">:</span> Helm    <span class="token key atrule">release</span><span class="token punctuation">:</span> harbor  <span class="token key atrule">annotations</span><span class="token punctuation">:</span>    <span class="token key atrule">cert-manager.io/cluster-issuer</span><span class="token punctuation">:</span> cluster<span class="token punctuation">-</span>letsencrypt<span class="token punctuation">-</span>prod<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">tls</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">hosts</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> harbor.domian.io      <span class="token key atrule">secretName</span><span class="token punctuation">:</span> harbor<span class="token punctuation">-</span>letsencrypt<span class="token punctuation">-</span>tls  <span class="token key atrule">rules</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">host</span><span class="token punctuation">:</span> harbor.domian.io      <span class="token key atrule">http</span><span class="token punctuation">:</span>        <span class="token key atrule">paths</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">path</span><span class="token punctuation">:</span> /            <span class="token key atrule">backend</span><span class="token punctuation">:</span>              <span class="token key atrule">serviceName</span><span class="token punctuation">:</span> harbor<span class="token punctuation">-</span>harbor<span class="token punctuation">-</span>portal              <span class="token key atrule">servicePort</span><span class="token punctuation">:</span> <span class="token number">80</span></code></pre><p>Ingress通过在annotations中添加cert-manager.io/cluster-issuer: cluster-letsencrypt-prod为ingress中的域名自动生成证书。</p><h2 id="四、Ingress应用ClusterIssuer-1"><a href="#四、Ingress应用ClusterIssuer-1" class="headerlink" title="四、Ingress应用ClusterIssuer"></a>四、Ingress应用ClusterIssuer</h2><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">kind</span><span class="token punctuation">:</span> Ingress<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> extensions/v1beta1<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> harbor<span class="token punctuation">-</span>ingress  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> ns<span class="token punctuation">-</span>harbor  <span class="token key atrule">labels</span><span class="token punctuation">:</span>    <span class="token key atrule">app</span><span class="token punctuation">:</span> harbor    <span class="token key atrule">chart</span><span class="token punctuation">:</span> harbor    <span class="token key atrule">heritage</span><span class="token punctuation">:</span> Helm    <span class="token key atrule">release</span><span class="token punctuation">:</span> harbor  <span class="token key atrule">annotations</span><span class="token punctuation">:</span>    <span class="token key atrule">cert-manager.io/issuer</span><span class="token punctuation">:</span> letsencrypt<span class="token punctuation">-</span>prod<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">tls</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">hosts</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> harbor.domian.io      <span class="token key atrule">secretName</span><span class="token punctuation">:</span> harbor<span class="token punctuation">-</span>letsencrypt<span class="token punctuation">-</span>tls  <span class="token key atrule">rules</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">host</span><span class="token punctuation">:</span> harbor.domian.io      <span class="token key atrule">http</span><span class="token punctuation">:</span>        <span class="token key atrule">paths</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">path</span><span class="token punctuation">:</span> /            <span class="token key atrule">backend</span><span class="token punctuation">:</span>              <span class="token key atrule">serviceName</span><span class="token punctuation">:</span> harbor<span class="token punctuation">-</span>harbor<span class="token punctuation">-</span>portal              <span class="token key atrule">servicePort</span><span class="token punctuation">:</span> <span class="token number">80</span></code></pre><p>Ingress通过在annotations中添加cert-manager.io/issuer: letsencrypt-prod为ingress中的域名自动生成证书。</p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2><ul><li>使用Cert Manager时，ingress中host配置的域名必须指定，不能有通配符；</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器化 </tag>
            
            <tag> Kubernetes优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes集群创建用户</title>
      <link href="/2019/12/31/kubernetes-ji-qun-chuang-jian-yong-hu/"/>
      <url>/2019/12/31/kubernetes-ji-qun-chuang-jian-yong-hu/</url>
      
        <content type="html"><![CDATA[<h1 id="创建集群用户"><a href="#创建集群用户" class="headerlink" title="创建集群用户"></a>创建集群用户</h1><p>1、创建用户</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> admin<span class="token punctuation">-</span>user  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>system<span class="token punctuation">---</span><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> rbac.authorization.k8s.io/v1beta1<span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRoleBinding<span class="token key atrule">metadata</span><span class="token punctuation">:</span>   <span class="token key atrule">name</span><span class="token punctuation">:</span> admin<span class="token punctuation">-</span>user  <span class="token key atrule">annotations</span><span class="token punctuation">:</span>    <span class="token key atrule">rbac.authorization.kubernetes.io/autoupdate</span><span class="token punctuation">:</span> <span class="token string">"true"</span><span class="token key atrule">roleRef</span><span class="token punctuation">:</span>  <span class="token key atrule">apiGroup</span><span class="token punctuation">:</span> rbac.authorization.k8s.io  <span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRole  <span class="token key atrule">name</span><span class="token punctuation">:</span> cluster<span class="token punctuation">-</span>admin<span class="token key atrule">subjects</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount  <span class="token key atrule">name</span><span class="token punctuation">:</span> admin<span class="token punctuation">-</span>user  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>system</code></pre><p>2、获取管理员用户的Token，通过执行如下命令获取系统Token信息</p><pre class=" language-sh"><code class="language-sh">kubectl describe secret admin-user --namespace=kube-system</code></pre><p>3、导入kubeconfig文件</p><pre class=" language-sh"><code class="language-sh">DASH_TOCKEN=$(kubectl get secret -n kube-system admin-user-token-4j272 -o jsonpath={.data.token}|base64 -d)kubectl config set-cluster kubernetes --server=https://172.16.0.9:8443 --kubeconfig=/root/kube-admin.confkubectl config set-credentials admin-user --token=$DASH_TOCKEN --kubeconfig=/root/kube-admin.confkubectl config set-context admin-user@kubernetes --cluster=kubernetes --user=admin-user --kubeconfig=/root/kube-admin.confkubectl config use-context admin-user@kubernetes --kubeconfig=/root/kube-admin.conf</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器化 </tag>
            
            <tag> Kubernetes优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes集群跨namespace服务访问</title>
      <link href="/2019/12/31/kubernetes-ji-qun-kua-namespace-fu-wu-fang-wen/"/>
      <url>/2019/12/31/kubernetes-ji-qun-kua-namespace-fu-wu-fang-wen/</url>
      
        <content type="html"><![CDATA[<h2 id="集群跨namespace服务访问"><a href="#集群跨namespace服务访问" class="headerlink" title="集群跨namespace服务访问"></a>集群跨namespace服务访问</h2><hr><p>ns-02需要访问ns-01下面的服务service01</p><hr><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> service02 <span class="token key atrule">namespace</span><span class="token punctuation">:</span> ns<span class="token punctuation">-</span><span class="token number">02</span><span class="token key atrule">spec</span><span class="token punctuation">:</span> <span class="token key atrule">ports</span><span class="token punctuation">:</span> <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> http   <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">80</span>   <span class="token key atrule">protocol</span><span class="token punctuation">:</span> TCP   <span class="token key atrule">targetPort</span><span class="token punctuation">:</span> <span class="token number">80</span> <span class="token key atrule">sessionAffinity</span><span class="token punctuation">:</span> None <span class="token key atrule">type</span><span class="token punctuation">:</span> ExternalName <span class="token key atrule">externalName</span><span class="token punctuation">:</span> service01.ns<span class="token punctuation">-</span>01.svc.cluster.local</code></pre><ul><li>externalName：需要访问的服务域名，service01指服务名字，ns-01指命名空间，svc.cluster.local指kubernetes内部服务域名结尾，默认是svc.cluster.local</li></ul><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器化 </tag>
            
            <tag> Kubernetes优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes集群创建Image Pull Secret</title>
      <link href="/2019/12/31/kubernetes-ji-qun-chuang-jian-image-pull-secret/"/>
      <url>/2019/12/31/kubernetes-ji-qun-chuang-jian-image-pull-secret/</url>
      
        <content type="html"><![CDATA[<h2 id="创建ImagePullSecret"><a href="#创建ImagePullSecret" class="headerlink" title="创建ImagePullSecret"></a>创建ImagePullSecret</h2><h3 id="一、登录镜像仓库，成功之后会生成如下-root-docker-config-json文件"><a href="#一、登录镜像仓库，成功之后会生成如下-root-docker-config-json文件" class="headerlink" title="一、登录镜像仓库，成功之后会生成如下/root/.docker/config.json文件"></a>一、登录镜像仓库，成功之后会生成如下/root/.docker/config.json文件</h3><pre class=" language-json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token property">"auths"</span><span class="token operator">:</span> <span class="token punctuation">{</span>        <span class="token property">"harbor.hnbcao.tech"</span><span class="token operator">:</span> <span class="token punctuation">{</span>            <span class="token property">"auth"</span><span class="token operator">:</span> <span class="token string">"YWRtaW4******lRlY2g="</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token property">"HttpHeaders"</span><span class="token operator">:</span> <span class="token punctuation">{</span>        <span class="token property">"User-Agent"</span><span class="token operator">:</span> <span class="token string">"Docker-Client/***"</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h3 id="二、执行如下命令创建ImagePullSecret"><a href="#二、执行如下命令创建ImagePullSecret" class="headerlink" title="二、执行如下命令创建ImagePullSecret"></a>二、执行如下命令创建ImagePullSecret</h3><pre class=" language-sh"><code class="language-sh">kubectl create secret generic harbor-admin-secret --from-file=.dockerconfigjson=/root/.docker/config.json --type=kubernetes.io/dockerconfigjson --namespace hnbcao-mixing-ore</code></pre><p>说明：</p><ul><li>harbor-admin-secret： ImagePullSecret名字</li><li>type： 指定secret类型为kubernetes.io/dockerconfigjson</li><li>namespace：secret命名空间</li></ul><h3 id="四、为项目添加ImagePullSecret"><a href="#四、为项目添加ImagePullSecret" class="headerlink" title="四、为项目添加ImagePullSecret"></a>四、为项目添加ImagePullSecret</h3><ul><li>Deployment</li></ul><p>在配置项的spec.template.spec.imagePullSecrets下添加secret：harbor-admin-secret。例如，Deployment的配置如下：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> app<span class="token punctuation">-</span>test<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">replicas</span><span class="token punctuation">:</span> <span class="token number">1</span>  <span class="token key atrule">selector</span><span class="token punctuation">:</span>    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>      <span class="token key atrule">app.kubernetes.io/instance</span><span class="token punctuation">:</span> app<span class="token punctuation">-</span>test      <span class="token key atrule">app.kubernetes.io/name</span><span class="token punctuation">:</span> hnbcao  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>      <span class="token key atrule">labels</span><span class="token punctuation">:</span>        <span class="token key atrule">app.kubernetes.io/instance</span><span class="token punctuation">:</span> app<span class="token punctuation">-</span>test        <span class="token key atrule">app.kubernetes.io/name</span><span class="token punctuation">:</span> hnbcao    <span class="token key atrule">spec</span><span class="token punctuation">:</span>      <span class="token key atrule">containers</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> hnbcao          <span class="token key atrule">image</span><span class="token punctuation">:</span> nginx      <span class="token key atrule">imagePullSecrets</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> harbor<span class="token punctuation">-</span>admin<span class="token punctuation">-</span>secret</code></pre><h3 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h3><p>附上官网教程：<a href="https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器化 </tag>
            
            <tag> Kubernetes优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes集群安装Traefik Ingress</title>
      <link href="/2019/12/31/kubernetes-ji-qun-an-zhuang-traefik-ingress/"/>
      <url>/2019/12/31/kubernetes-ji-qun-an-zhuang-traefik-ingress/</url>
      
        <content type="html"><![CDATA[<h2 id="部署TraefikIngress"><a href="#部署TraefikIngress" class="headerlink" title="部署TraefikIngress"></a>部署TraefikIngress</h2><h3 id="使用OpenSSL创建TLS证书（已有证书则跳过该选项）"><a href="#使用OpenSSL创建TLS证书（已有证书则跳过该选项）" class="headerlink" title="使用OpenSSL创建TLS证书（已有证书则跳过该选项）"></a>使用OpenSSL创建TLS证书（已有证书则跳过该选项）</h3><ul><li>设置证书信息</li></ul><pre class=" language-sh"><code class="language-sh">cd ~ && mkdir tls echo """[req] distinguished_name = req_distinguished_nameprompt = yes[ req_distinguished_name ]countryName                     = Country Name (2 letter code)countryName_value               = CNstateOrProvinceName             = State or Province Name (full name)stateOrProvinceName_value       = ChongqinglocalityName                    = Locality Name (eg, city)localityName_value              = YubeiorganizationName                = Organization Name (eg, company)organizationName_value          = HNBCAOorganizationalUnitName          = Organizational Unit Name (eg, section)organizationalUnitName_value    = R & D DepartmentcommonName                      = Common Name (eg, your name or your server\'s hostname)commonName_value                = *.hnbcao.ioemailAddress                    = Email AddressemailAddress_value              = hnbcao@163.com""" > ~/tls/openssl.cnf</code></pre><ul><li>生成证书</li></ul><pre class=" language-sh"><code class="language-sh">openssl req -newkey rsa:4096 -nodes -config ~/tls/openssl.cnf -days 3650 -x509 -out ~/tls/tls.crt -keyout ~/tls/tls.key</code></pre><h3 id="部署Traefik"><a href="#部署Traefik" class="headerlink" title="部署Traefik"></a>部署Traefik</h3><ul><li>添加证书至集群</li></ul><pre class=" language-sh"><code class="language-sh">kubectl create -n kube-system secret tls ssl --cert ~/ikube/tls/tls.crt --key ~/ikube/tls/tls.key</code></pre><ul><li>部署Traefik</li></ul><pre class=" language-sh"><code class="language-sh">kubectl apply -f https://raw.githubusercontent.com/hnbcao/kubeadm-ha/master/addons/yaml/traefik/traefik-daemonset-full.yaml</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器化 </tag>
            
            <tag> Kubernetes优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes集群安装</title>
      <link href="/2019/12/31/kubernetes-ji-qun-an-zhuang/"/>
      <url>/2019/12/31/kubernetes-ji-qun-an-zhuang/</url>
      
        <content type="html"><![CDATA[<h2 id="Kubernetes集群搭建"><a href="#Kubernetes集群搭建" class="headerlink" title="Kubernetes集群搭建"></a>Kubernetes集群搭建</h2><ul><li>1、本文基于<a href="https://www.kubernetes.org.cn/4948.html" target="_blank" rel="noopener">kubeadm HA master(v1.13.0)离线包 + 自动化脚本 + 常用插件 For Centos/Fedora</a>编写，修改了master之间的负载均衡方式为HAProxy+keeplived方式。</li><li>2、此离线教程必须保证目标安装环境与离线包下载环境一致，或者是考虑做yum镜像源。</li><li>3、关于keepalived+haproxy负载均衡，由于是在阿里云上搭建的，事实上是没有实现的，至于为何也成功部署了环境，其实是每台机器上keepalived都处于激活状态，对虚拟ip的访问都映射到了本机，本机又通过haproxy将请求负载到了api-server上。这是个神奇的事情，直到现在才搞清楚keepalived+haproxy的原理，如果是在阿里云上部署，这块建议使用阿里云的负载均衡功能。（keepalived+haproxy是为了实现api-server的负载均衡）</li><li>4、关于内核，实际上升不升级应该问题都不是很大，至少目前环境没出现过问题。</li><li>5、关于kubernetes版本，目前该教程能支持最新的v1.15.3版本的安装，注意修改版本号。</li></ul><p>集群方案：</p><ul><li>发行版：CentOS 7</li><li>容器运行时</li><li>内核： 4.18.12-1.el7.elrepo.x86_64</li><li>版本：Kubernetes: 1.14.0</li><li>网络方案: Calico</li><li>kube-proxy mode: IPVS</li><li>master高可用方案：HAProxy keepalived LVS</li><li>DNS插件: CoreDNS</li><li>metrics插件：metrics-server</li><li>界面：kubernetes-dashboard</li></ul><h3 id="一、环境概述"><a href="#一、环境概述" class="headerlink" title="一、环境概述"></a>一、环境概述</h3><table><thead><tr><th>Host Name</th><th>Role</th><th>IP</th></tr></thead><tbody><tr><td>master1</td><td>master1</td><td>192.168.56.103</td></tr><tr><td>master2</td><td>master2</td><td>192.168.56.104</td></tr><tr><td>master3</td><td>master3</td><td>192.168.56.105</td></tr><tr><td>node1</td><td>node1</td><td>192.168.56.106</td></tr><tr><td>node2</td><td>node2</td><td>192.168.56.107</td></tr><tr><td>node3</td><td>node3</td><td>192.168.56.108</td></tr></tbody></table><h3 id="二、安装包准备（可选）"><a href="#二、安装包准备（可选）" class="headerlink" title="二、安装包准备（可选）"></a>二、安装包准备（可选）</h3><pre class=" language-sh"><code class="language-sh"># 设置yum缓存路径，cachedir 缓存路径 keepcache=1保持安装包在软件安装之后不删除cat /etc/yum.conf  [main]cachedir=/home/yumkeepcache=1# 安装ifconfigyum install net-tools -y# 时间同步yum install -y ntpdate# 安装docker（建议18.06.3.ce）yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repoyum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum makecache fast## 列出Docker版本yum list docker-ce --showduplicates | sort -r## 安装指定版本sudo yum install docker-ce-<VERSION_STRING>eg:sudo yum install docker-ce-18.06.3.ce# 安装文件管理器，XShell可通过rz sz命令上传或者下载服务器文件yum install lrzsz -y# 安装keepalived、haproxyyum install -y socat keepalived ipvsadm haproxy# 安装kubernetes相关组件cat <<EOF > /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg        http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 建议指定各个软件的版本号，使用yum list 软件名（如kubelet） --showduplicates | sort -r列出版本号。yum install -y kubelet kubeadm kubectl ebtables# 其他软件安装yum install wget# 拷贝离线包到集群节点# 离线安装，需要包下载服务器与安装服务器系统版本等同步。建议采用离线镜像源的方式。# rpm -ivh *.rpm --force --nodepsrpm -ivh ./base/packages/*.rpm --nodeps --forcerpm -ivh ./docker-ce-stable/packages/*.rpm --nodeps --forcerpm -ivh ./extras/packages/*.rpm --nodeps --forcerpm -ivh ./kubernetes/packages/*.rpm --nodeps --forcerpm -ivh ./updates/packages/*.rpm --nodeps --force</code></pre><h3 id="三、节点系统配置"><a href="#三、节点系统配置" class="headerlink" title="三、节点系统配置"></a>三、节点系统配置</h3><ul><li>关闭SELinux、防火墙</li></ul><pre class=" language-sh"><code class="language-sh">systemctl stop firewalldsystemctl disable firewalldsetenforce 0sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config</code></pre><ul><li>关闭系统的Swap（Kubernetes 1.8开始要求）</li></ul><pre class=" language-sh"><code class="language-sh">swapoff -ayes | cp /etc/fstab /etc/fstab_bakcat /etc/fstab_bak |grep -v swap > /etc/fstab</code></pre><ul><li>配置L2网桥在转发包时会被iptables的FORWARD规则所过滤，该配置被CNI插件需要，更多信息请参考<a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#network-plugin-requirements" target="_blank" rel="noopener">Network Plugin Requirements</a></li></ul><pre class=" language-sh"><code class="language-sh">echo """vm.swappiness = 0net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1""" > /etc/sysctl.confsysctl -p</code></pre><p><a href="https://www.cnblogs.com/zejin2008/p/7102485.html" target="_blank" rel="noopener">centos7添加bridge-nf-call-ip6tables出现No such file or directory</a>,简单来说就是执行一下 modprobe br_netfilter</p><ul><li>同步时间</li></ul><pre class=" language-sh"><code class="language-sh">ntpdate -u ntp.api.bz</code></pre><ul><li>升级内核到最新（已准备内核离线安装包，可选）</li></ul><p><a href="https://www.aliyun.com/jiaocheng/130885.html" target="_blank" rel="noopener">centos7 升级内核</a></p><p><a href="https://www.kubernetes.org.cn/5163.html" target="_blank" rel="noopener">参考文章</a></p><pre class=" language-sh"><code class="language-sh">grub2-set-default 0 && grub2-mkconfig -o /etc/grub2.cfggrubby --default-kernelgrubby --args="user_namespace.enable=1" --update-kernel="$(grubby --default-kernel)"</code></pre><ul><li>重启系统，确认内核版本后，开启IPVS（如果未升级内核，去掉ip_vs_fo）</li></ul><pre class=" language-sh"><code class="language-sh">uname -acat > /etc/sysconfig/modules/ipvs.modules <<EOF#!/bin/bashipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack"for kernel_module in \${ipvs_modules}; do /sbin/modinfo -F filename \${kernel_module} > /dev/null 2>&1 if [ $? -eq 0 ]; then /sbin/modprobe \${kernel_module} fidoneEOFchmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep ip_vs</code></pre><p>执行sysctl -p报错可执行modprobe br_netfilter，请参考<a href="https://www.cnblogs.com/zejin2008/p/7102485.html" target="_blank" rel="noopener">centos7添加bridge-nf-call-ip6tables出现No such file or directory</a></p><ul><li>所有机器需要设定/etc/sysctl.d/k8s.conf的系统参数(可选)</li></ul><pre class=" language-sh"><code class="language-sh"># https://github.com/moby/moby/issues/31208 # ipvsadm -l --timout# 修复ipvs模式下长连接timeout问题 小于900即可cat <<EOF > /etc/sysctl.d/k8s.confnet.ipv4.tcp_keepalive_time = 600net.ipv4.tcp_keepalive_intvl = 30net.ipv4.tcp_keepalive_probes = 10net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1net.ipv4.neigh.default.gc_stale_time = 120net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_announce = 2net.ipv4.ip_forward = 1net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 1024net.ipv4.tcp_synack_retries = 2net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.netfilter.nf_conntrack_max = 2310720fs.inotify.max_user_watches=89100fs.may_detach_mounts = 1fs.file-max = 52706963fs.nr_open = 52706963net.bridge.bridge-nf-call-arptables = 1vm.swappiness = 0vm.overcommit_memory=1vm.panic_on_oom=0EOFsysctl --system</code></pre><ul><li>设置开机启动</li></ul><pre class=" language-sh"><code class="language-sh"># 启动dockersed -i "13i ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT" /usr/lib/systemd/system/docker.servicesystemctl daemon-reloadsystemctl enable dockersystemctl start docker# 设置kubelet开机启动systemctl enable kubeletsystemctl enable keepalivedsystemctl enable haproxy</code></pre><ul><li>设置免密登录</li></ul><pre class=" language-sh"><code class="language-sh"># 1、三次回车后，密钥生成完成ssh-keygen# 2、拷贝密钥到其他节点ssh-copy-id -i ~/.ssh/id_rsa.pub  用户名字@192.168.x.xxx</code></pre><p>**、 Kubernetes要求集群中所有机器具有不同的Mac地址、产品uuid、Hostname。</p><h3 id="四、keepalived-haproxy配置"><a href="#四、keepalived-haproxy配置" class="headerlink" title="四、keepalived+haproxy配置"></a>四、keepalived+haproxy配置</h3><pre class=" language-sh"><code class="language-sh">cd ~/# 创建集群信息文件echo """CP0_IP=192.168.56.103CP1_IP=192.168.56.103CP2_IP=192.168.56.104VIP=192.168.56.102NET_IF=eth0CIDR=10.244.0.0/16""" > ./cluster-infobash -c "$(curl -fsSL https://raw.githubusercontent.com/hnbcao/kubeadm-ha-master/v1.14.0/keepalived-haproxy.sh)"</code></pre><p>安装Keepalived、Haproxy</p><ul><li><p>这是个错误的操作，并不需要在node部署keepalived+haproxy，如果node节点无法ping通虚拟IP（VIP），其原因是当前环境无法实现vip，具体原因由于能力有限，只能麻烦自己找找咯，方便分享的话不胜感激。</p></li><li><p>各个节点需要配置keepalived 和 haproxy</p></li></ul><pre class=" language-sh"><code class="language-sh">#/etc/haproxy/haproxy.cfgglobal    log         127.0.0.1 local2    chroot      /var/lib/haproxy    pidfile     /var/run/haproxy.pid    maxconn     4000    user        haproxy    group       haproxy    daemon    stats socket /var/lib/haproxy/statsdefaults    mode                    tcp    log                     global    option                  tcplog    option                  dontlognull    option                  redispatch    retries                 3    timeout queue           1m    timeout connect         10s    timeout client          1m    timeout server          1m    timeout check           10s    maxconn                 3000listen stats    mode   http    bind :10086    stats   enable    stats   uri     /admin?stats    stats   auth    admin:admin    stats   admin   if TRUEfrontend  k8s_https *:8443    mode      tcp    maxconn      2000    default_backend     https_sribackend https_sri    balance      roundrobin    server master1-api ${MASTER1_IP}:6443  check inter 10000 fall 2 rise 2 weight 1    server master2-api ${MASTER2_IP}:6443  check inter 10000 fall 2 rise 2 weight 1    server master3-api ${MASTER3_IP}:6443  check inter 10000 fall 2 rise 2 weight 1</code></pre><pre class=" language-sh"><code class="language-sh">#/etc/keepalived/keepalived.conf global_defs {    router_id LVS_DEVEL}vrrp_script check_haproxy {    script /etc/keepalived/check_haproxy.sh    interval 3}vrrp_instance VI_1 {    state MASTER    interface eth0    virtual_router_id 80    priority 100    advert_int 1    authentication {        auth_type PASS        auth_pass just0kk    }    virtual_ipaddress {        ${VIP}/24    }    track_script {           check_haproxy    }}</code></pre><pre class=" language-sh"><code class="language-sh">/etc/keepalived/check_haproxy.sh#!/bin/bashA=`ps -C haproxy --no-header |wc -l`if [ $A -eq 0 ];then/etc/init.d/keepalived stopfi</code></pre><p>注意两个配置中的${MASTER1 _ IP}, ${MASTER2 _ IP}, ${MASTER3 _ IP}、${VIP}需要替换为自己集群相应的IP地址</p><ul><li>重启keepalived和haproxy</li></ul><pre class=" language-sh"><code class="language-sh">systemctl stop keepalivedsystemctl enable keepalivedsystemctl start keepalivedsystemctl stop haproxysystemctl enable haproxysystemctl start haproxy</code></pre><h3 id="五、部署HA-Master"><a href="#五、部署HA-Master" class="headerlink" title="五、部署HA Master"></a>五、部署HA Master</h3><p>HA Master的部署过程已经自动化，请在master-1上执行如下命令，并注意修改IP;</p><p>脚本主要执行三步：</p><p>1)、重置kubelet设置</p><pre class=" language-sh"><code class="language-sh">kubeadm reset -frm -rf /etc/kubernetes/pki/</code></pre><p>2)、编写节点配置文件并初始化master1的kubelet</p><pre class=" language-sh"><code class="language-sh">echo """apiVersion: kubeadm.k8s.io/v1beta1kind: ClusterConfigurationkubernetesVersion: v1.14.0controlPlaneEndpoint: "${VIP}:8443"maxPods: 100networkPlugin: cniimageRepository: registry.aliyuncs.com/google_containersapiServer:  certSANs:  - ${CP0_IP}  - ${CP1_IP}  - ${CP2_IP}  - ${VIP}networking:  # This CIDR is a Calico default. Substitute or remove for your CNI provider.  podSubnet: ${CIDR}---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationmode: ipvs""" > /etc/kubernetes/kubeadm-config.yamlkubeadm init --config /etc/kubernetes/kubeadm-config.yamlmkdir -p $HOME/.kubecp -f /etc/kubernetes/admin.conf ${HOME}/.kube/config</code></pre><ul><li>关于默认网关问题，如果有多张网卡，需要先将默认网关切换到集群使用的那张网卡上，否则可能会出现etcd无法连接等问题。（应用我用的虚拟机，有一张网卡无法做到各个节点胡同；route查看当前网关信息，route del default删除默认网关，route add default enth0设置默认网关enth0为网卡名）</li></ul><p>3)、拷贝相关证书到master2、master3</p><pre class=" language-sh"><code class="language-sh">for index in 1 2; do  ip=${IPS[${index}]}  ssh $ip "mkdir -p /etc/kubernetes/pki/etcd; mkdir -p ~/.kube/"  scp /etc/kubernetes/pki/ca.crt $ip:/etc/kubernetes/pki/ca.crt  scp /etc/kubernetes/pki/ca.key $ip:/etc/kubernetes/pki/ca.key  scp /etc/kubernetes/pki/sa.key $ip:/etc/kubernetes/pki/sa.key  scp /etc/kubernetes/pki/sa.pub $ip:/etc/kubernetes/pki/sa.pub  scp /etc/kubernetes/pki/front-proxy-ca.crt $ip:/etc/kubernetes/pki/front-proxy-ca.crt  scp /etc/kubernetes/pki/front-proxy-ca.key $ip:/etc/kubernetes/pki/front-proxy-ca.key  scp /etc/kubernetes/pki/etcd/ca.crt $ip:/etc/kubernetes/pki/etcd/ca.crt  scp /etc/kubernetes/pki/etcd/ca.key $ip:/etc/kubernetes/pki/etcd/ca.key  scp /etc/kubernetes/admin.conf $ip:/etc/kubernetes/admin.conf  scp /etc/kubernetes/admin.conf $ip:~/.kube/config  ssh ${ip} "${JOIN_CMD} --control-plane"done</code></pre><p>4)、master2、master3加入节点</p><pre class=" language-sh"><code class="language-sh">JOIN_CMD=`kubeadm token create --print-join-command`ssh ${ip} "${JOIN_CMD} --control-plane"</code></pre><p>完整脚本：</p><pre class=" language-sh"><code class="language-sh"># 部署HA masterbash -c "$(curl -fsSL https://raw.githubusercontent.com/hnbcao/kubeadm-ha-master/v1.14.0/kube-ha.sh)"</code></pre><h3 id="六、加入节点"><a href="#六、加入节点" class="headerlink" title="六、加入节点"></a>六、加入节点</h3><ul><li>节点加入命令获取</li></ul><pre class=" language-sh"><code class="language-sh">#master节点执行该命令，再在节点执行获取到的命令kubeadm token create --print-join-command</code></pre><h3 id="七、结束安装"><a href="#七、结束安装" class="headerlink" title="七、结束安装"></a>七、结束安装</h3><p>此时集群还需要安装网络组件，我选择了calico。具体安装方式可访问<a href="https://www.projectcalico.org/" target="_blank" rel="noopener">calico官网</a>，或者运行本仓库里面addons/calico下的配置。注意替换里面的镜像和Deployment里面的环境变量CALICO_IPV4POOL_CIDR为/etc/kubernetes/kubeadm-config.yaml里面networking.podSubnet的值。</p><p>文章只是在文章<a href="https://www.kubernetes.org.cn/4948.html" target="_blank" rel="noopener">kubeadm HA master(v1.13.0)离线包 + 自动化脚本 + 常用插件 For Centos/Fedora</a>的基础上，修改了master的HA方案。关于集群安装的详细步骤，建议访问<a href="https://www.kubernetes.org.cn/4948.html" target="_blank" rel="noopener">kubeadm HA master(v1.13.0)离线包 + 自动化脚本 + 常用插件 For Centos/Fedora</a>。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 运维 </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器化 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
