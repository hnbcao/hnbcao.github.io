<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on HNBCAO</title>
    <link>https://hnbcao.vip/</link>
    <description>Recent content in Introduction on HNBCAO</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zn-ch</language>
    <lastBuildDate>Tue, 16 Jun 2020 14:16:38 +0000</lastBuildDate><atom:link href="https://hnbcao.vip/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>1. 上下文 Context</title>
      <link>https://hnbcao.vip/docs/golang/runtime/context/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/golang/runtime/context/</guid>
      <description>上下文 Context #  1.1. 方法实现 #  context.Context 是 Go 语言在 1.7 版本中引入标准库的接口1，该接口定义了四个需要实现的方法，其中包括：
  Deadline — 返回 context.Context 被取消的时间，也就是完成工作的截止日期；
  Done — 返回一个 Channel，这个 Channel 会在当前工作完成或者上下文被取消后关闭，多次调用 Done 方法会返回同一个 Channel；
  Err — 返回 context.Context 结束的原因，它只会在 Done 方法对应的 Channel 关闭时返回非空的值；
  如果 context.Context 被取消，会返回 Canceled 错误；
  如果 context.Context 超时，会返回 DeadlineExceeded 错误；
    Value — 从 context.Context 中获取键对应的值，对于同一个上下文来说，多次调用 Value 并传入相同的 Key 会返回相同的结果，该方法可以用来传递请求特定的数据；</description>
    </item>
    
    <item>
      <title>1. 语言基础</title>
      <link>https://hnbcao.vip/docs/golang/basic/basic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/golang/basic/basic/</guid>
      <description>语言基础 #  1.1. 数组和切片 #  循环永动机：对于所有的 range 循环，Go 语言都会在编译期将原切片或者数组赋值给一个新变量 ha，在赋值的过程中就发生了拷贝，而我们又通过 len 关键字预先获取了切片的长度，所以在循环中追加新的元素也不会改变循环执行的次数，这也就解释了循环永动机一节提到的现象。
1.2. 哈希表 #  首先会选出一个绿色的正常桶开始遍历，随后遍历所有黄色的溢出桶，最后依次按照索引顺序遍历哈希表中其他的桶，直到所有的桶都被遍历完成。
1.3. 字符串 #  遍历字符串时拿到的值都是 rune 类型的变量，for i, r := range s {} 的结构都会被转换成如下所示的形式：
ha := s for hv1 := 0; hv1 &amp;lt; len(ha); { hv1t := hv1 hv2 := rune(ha[hv1]) if hv2 &amp;lt; utf8.RuneSelf { hv1++ } else { hv2, hv1 = decoderune(ha, hv1) } v1, v2 = hv1t, hv2 } 1.</description>
    </item>
    
    <item>
      <title>1. 逃逸分析</title>
      <link>https://hnbcao.vip/docs/golang/advanced/escape_analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/golang/advanced/escape_analysis/</guid>
      <description>逃逸分析 #  1.1. 什么是逃逸分析？ #  逃逸分析（Escape analysis）: 由语言决定变量分配到堆上还是栈上。在Java中，逃逸分析是在运行时发生；在Go语言中，逃逸分析在编译期间完成，编译器决定内存分配的位置，不需要程序员指定。
在函数中申请一个新的对象：
 如果分配在栈中，则函数执行结束可自动将内存回收； 如果分配在堆中，则函数执行结束可交给GC（垃圾回收）处理;  逃逸分析针对指针和大对象：除大对象外，一个值引用变量如果没有被取址，那么它永远不可能逃逸。
1.2. 逃逸场景 #  指针逃逸、动态类型逃逸、闭包引用对象逃逸属于指针逃逸，都会发生指针的传递；栈空间不足逃逸属于大对象逃逸，不一定有值传递，这种场景是由于对象过大，无法在栈上分配导致。
  指针逃逸： Go可以返回局部变量指针，示例代码如下：
package main type User struct { Name string } func main() { user := structFunc() user.Name = &amp;#34;2&amp;#34; } func structFunc() *User { // 局部变量user逃逸到堆 	user := &amp;amp;User{ Name: &amp;#34;123&amp;#34;, } user.Name = &amp;#34;234&amp;#34; return user } user 本身为一指针，其值通过函数返回值返回，其指向的内存地址不会是栈而是堆，这就是典型的逃逸案例，如果返回值不是指针而是值，此时会发生值拷贝，不会出现逃逸分析。
  动态类型逃逸（不确定长度大小）:很多函数参数为interface类型，比如fmt.Println(a …interface{})，编译期间很难确定其参数的具体类型，也能产生逃逸。
如下代码所示：</description>
    </item>
    
    <item>
      <title>2. 同步原语与锁</title>
      <link>https://hnbcao.vip/docs/golang/runtime/mutex/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/golang/runtime/mutex/</guid>
      <description>同步原语与锁 #  2.1. 概述 #  ​	本节会介绍 Go 语言中常见的同步原语 sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Once 和 sync.Cond 以及扩展原语 golang/sync/errgroup.Group、golang/sync/semaphore.Weighted 和 golang/sync/singleflight.Group 的实现原理，同时也会涉及互斥锁、信号量等并发编程中的常见概念。
2.2. 互斥锁（Mutex） #  2.2.1 正常模式和饥饿模式 #  sync.Mutex 有两种模式 — 正常模式和饥饿模式。我们需要在这里先了解正常模式和饥饿模式都是什么以及它们有什么样的关系。
在正常模式下，锁的等待者会按照先进先出的顺序获取锁。但是刚被唤起的 Goroutine 与新创建的 Goroutine 竞争时，大概率会获取不到锁，为了减少这种情况的出现，一旦 Goroutine 超过 1ms 没有获取到锁，它就会将当前互斥锁切换饥饿模式，防止部分 Goroutine 被『饿死』。
在饥饿模式中，互斥锁会直接交给等待队列最前面的 Goroutine。新的 Goroutine 在该状态下不能获取锁、也不会进入自旋状态，它们只会在队列的末尾等待。如果一个 Goroutine 获得了互斥锁并且它在队列的末尾或者它等待的时间少于 1ms，那么当前的互斥锁就会切换回正常模式。
2.2.2 加锁和解锁 #  如果互斥锁的状态不是 0 时就会调用 sync.Mutex.lockSlow 尝试通过自旋（Spinnig）等方式等待锁的释放，该方法的主体是一个非常大 for 循环，这里将它分成几个部分介绍获取锁的过程：
 判断当前 Goroutine 能否进入自旋； 通过自旋等待互斥锁的释放； 计算互斥锁的最新状态； 更新互斥锁的状态并获取锁；  2.2.3 自旋的条件 #  Goroutine 进入自旋的条件非常苛刻：</description>
    </item>
    
    <item>
      <title>With ToC</title>
      <link>https://hnbcao.vip/docs/example/table-of-contents/with-toc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/example/table-of-contents/with-toc/</guid>
      <description>Caput vino delphine in tamen vias #  Cognita laeva illo fracta #  Lorem markdownum pavent auras, surgit nunc cingentibus libet Laomedonque que est. Pastor An arbor filia foedat, ne fugit aliter, per. Helicona illas et callida neptem est Oresitrophos caput, dentibus est venit. Tenet reddite famuli praesentem fortibus, quaeque vis foret si frondes gelidos gravidae circumtulit inpulit armenta nativum.
 Te at cruciabere vides rubentis manebo Maturuit in praetemptat ruborem ignara postquam habitasse Subitarum supplevit quoque fontesque venabula spretis modo Montis tot est mali quasque gravis Quinquennem domus arsit ipse Pellem turis pugnabant locavit  Natus quaerere #  Pectora et sine mulcere, coniuge dum tincta incurvae.</description>
    </item>
    
    <item>
      <title>2. 常用关键字</title>
      <link>https://hnbcao.vip/docs/golang/basic/keyword/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/golang/basic/keyword/</guid>
      <description>常用关键字 #  2.1. Select #  2.1.1. 实现原理 #    直接阻塞：空 select 语句；空的 select 语句会直接阻塞当前的 Goroutine，导致 Goroutine 进入无法被唤醒的永久休眠状态。
  单一管道：select 条件只包含一个 case；如果当前的 select 条件只包含一个 case，当 case 中的 Channel 是空指针时，就会直接挂起当前 Goroutine 并永久休眠。
  非阻塞操作：当 select 中仅包含两个 case，并且其中一个是 default 时，Go 语言的编译器就会认为这是一次非阻塞的收发操作。如果 select 控制结构中包含 default 语句，那么这个 select 语句在执行时会遇到以下两种情况：
1.当存在可以收发的 Channel 时，直接处理该 Channel 对应的 case；
2.当不存在可以收发的 Channel 是，执行 default 中的语句；
当我们运行下面的代码时就不会阻塞当前的 Goroutine，它会直接执行 default 中的代码并返回。
func main() { ch := make(chan int) select { case i := &amp;lt;-ch: println(i) default: println(&amp;#34;default&amp;#34;) } }   2.</description>
    </item>
    
    <item>
      <title>Without ToC</title>
      <link>https://hnbcao.vip/docs/example/table-of-contents/without-toc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/example/table-of-contents/without-toc/</guid>
      <description>At me ipso nepotibus nunc celebratior genus #  Tanto oblite #  Lorem markdownum pectora novis patenti igne sua opus aurae feras materiaque illic demersit imago et aristas questaque posset. Vomit quoque suo inhaesuro clara. Esse cumque, per referri triste. Ut exponit solisque communis in tendens vincetis agisque iamque huic bene ante vetat omina Thebae rates. Aeacus servat admonitu concidit, ad resimas vultus et rugas vultu dignamque Siphnon.
Quam iugulum regia simulacra, plus meruit humo pecorumque haesit, ab discedunt dixit: ritu pharetramque.</description>
    </item>
    
    <item>
      <title>About This Blog</title>
      <link>https://hnbcao.vip/posts/me/</link>
      <pubDate>Sun, 28 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/posts/me/</guid>
      <description>Introduction #  记录工作记录以及学习笔记。</description>
    </item>
    
    <item>
      <title>设计模式简介</title>
      <link>https://hnbcao.vip/docs/design/design-pattern/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/design/design-pattern/</guid>
      <description>设计模式简介 #  一、设计模式原则 #    开闭原则：开闭原则（Open Closed Principle，OCP）由勃兰特·梅耶（Bertrand Meyer）提出，他在 1988 年的著作《面向对象软件构造》（Object Oriented Software Construction）中提出：软件实体应当对扩展开放，对修改关闭（Software entities should be open for extension，but closed for modification），这就是开闭原则的经典定义。
  里氏替换原则：里氏替换原则（Liskov Substitution Principle，LSP）由麻省理工学院计算机科学实验室的里斯科夫（Liskov）女士在 1987 年的“面向对象技术的高峰会议”（OOPSLA）上发表的一篇文章《数据抽象和层次》（Data Abstraction and Hierarchy）里提出来的，她提出：继承必须确保超类所拥有的性质在子类中仍然成立（Inheritance should ensure that any property proved about supertype objects also holds for subtype objects）。
  依赖倒置原则：依赖倒置原则（Dependence Inversion Principle，DIP）的原始定义为，高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象（High level modules shouldnot depend upon low level modules.Both should depend upon abstractions.Abstractions should not depend upon details.</description>
    </item>
    
    <item>
      <title>Docker Compose安装使用</title>
      <link>https://hnbcao.vip/docs/container/docker/docker-compose-installation/</link>
      <pubDate>Tue, 17 Mar 2020 15:42:28 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/container/docker/docker-compose-installation/</guid>
      <description>Docker Compose安装使用 #  一、概述 #  Compose是用于定义和运行多容器Docker应用程序的工具。通过Compose，您可以使用YAML文件来配置应用程序的服务。然后，使用一个命令，就可以从配置中创建并启动所有服务。
使用Compose基本上是一个三步过程：
 打包应用镜像 使用docker-compose.yml文件定义应用服务 运行docker-compose up 启动服务  如下是一个redis服务的docker-compose.yml文件：
version: &amp;#39;2.0&amp;#39; services: web: build: . ports: - &amp;#34;5000:5000&amp;#34; volumes: - .:/code - logvolume01:/var/log links: - redis redis: image: redis volumes: logvolume01: {} Compose是用于定义和运行多容器应用的工具。通过Compose，您可以使用YAML文件来配置应用程序的服务。然后，使用一个命令，就可以从配置中创建并启动所有服务。例如：一个Wordpress项目包含mysql数据库和wordpress应用，首先创建docker-compose.yml文件（建议在wordpress文件夹下创建，方便管理），然后在docker-compose.yml文件所在的目录下运行“docker-compose up -d”，Compose就会通过配置创建并启动Wordpress。
二、安装 #  系统环境
   Host Name OS IP     master1 CentOS 7.5 192.168.56.114    通过如下命令下载Docker Compose
# 下载docker-compose-1.25.4并保存至/usr/local/bin/目录下 sudo curl -L &amp;#34;https://github.</description>
    </item>
    
    <item>
      <title>Kubernetes集群安装</title>
      <link>https://hnbcao.vip/docs/container/kubernetes/1-kubernetes-cluster-installation/</link>
      <pubDate>Tue, 31 Dec 2019 16:16:02 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/container/kubernetes/1-kubernetes-cluster-installation/</guid>
      <description>Kubernetes集群搭建 #  一、概述 #   本文基于kubeadm HA master(v1.13.0)离线包 + 自动化脚本 + 常用插件 For Centos/Fedora编写，修改了master之间的负载均衡方式为HAProxy+keeplived方式。 此离线教程必须保证目标安装环境与离线包下载环境一致，或者是考虑做yum镜像源。 关于keepalived+haproxy负载均衡，由于是在阿里云上搭建的，事实上是没有实现的，至于为何也成功部署了环境，其实是每台机器上keepalived都处于激活状态，对虚拟ip的访问都映射到了本机，本机又通过haproxy将请求负载到了api-server上。这是个神奇的事情，直到现在才搞清楚keepalived+haproxy的原理，如果是在阿里云上部署，这块建议使用阿里云的负载均衡功能。（keepalived+haproxy是为了实现api-server的负载均衡） 关于内核，实际上升不升级应该问题都不是很大，至少目前环境没出现过问题。 关于kubernetes版本，目前该教程能支持最新的v1.15.3版本的安装，注意修改版本号。  集群方案：
 发行版：CentOS 7 容器运行时 内核： 4.18.12-1.el7.elrepo.x86_64 版本：Kubernetes: 1.14.0 网络方案: Calico kube-proxy mode: IPVS master高可用方案：HAProxy keepalived LVS DNS插件: CoreDNS metrics插件：metrics-server 界面：kubernetes-dashboard  二、安装环境 #     Host Name Role IP     master1 master1 192.168.56.103   master2 master2 192.168.56.104   master3 master3 192.168.56.105   node1 node1 192.</description>
    </item>
    
    <item>
      <title>Canal安装部署</title>
      <link>https://hnbcao.vip/docs/seo/middleware/canal-installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/seo/middleware/canal-installation/</guid>
      <description>canal安装部署 #  一、概述 #  canal版本：1.1.5
二、安装Zookeeper #  三、MySQL配置 #   对于自建 MySQL , 需要先开启 Binlog 写入功能，配置 binlog-format 为 ROW 模式，my.cnf 中配置如下  [mysqld] log-bin=mysql-bin # 开启 binlog binlog-format=ROW # 选择 ROW 模式 server_id=1 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复  授权 canal 链接 MySQL 账号具有作为 MySQL slave 的权限, 如果已有账户可直接 grant  CREATE USER canal IDENTIFIED BY &#39;canal&#39;; GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.</description>
    </item>
    
    <item>
      <title>CentOS离线镜像仓库创建</title>
      <link>https://hnbcao.vip/docs/seo/system/create-offline-yum-repo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/seo/system/create-offline-yum-repo/</guid>
      <description>CentOS离线镜像仓库创建-以base仓库为例 #  一、安装相关软件 #  yum install createrepo reposync yum-utils -y 二、替换镜像源 #   备份  mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/   Aliyun源地址为：https://developer.aliyun.com/mirror/  CentOS 7
wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo 或者
curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo 三、同步镜像&amp;amp;创建本地仓库 #  # 新建文件夹，存储同步的仓库数据 mkdir -p /data/yum.repo &amp;amp;&amp;amp; cd /data/yum.repo # 镜像仓库同步 reposync -r base -p ./ # 创建本地仓库 cd base &amp;amp;&amp;amp; createrepo ./ 四、离线服务器使用 #    将同步的镜像仓库打包到离线服务器上，并解压至/mnt/yum.</description>
    </item>
    
    <item>
      <title>Kubernetes集群安装Cert Manager</title>
      <link>https://hnbcao.vip/docs/container/kubernetes/2-kubernetes-cert-manager/</link>
      <pubDate>Tue, 31 Dec 2019 17:31:17 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/container/kubernetes/2-kubernetes-cert-manager/</guid>
      <description>安装Cert Manager #  一、安装 #  https://cert-manager.io/docs/installation/kubernetes/
二、创建ClusterIssuer #  集群内所有命名空间公用方案
apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: cluster-letsencrypt-prod spec: acme: email: hnbcao@qq.com privateKeySecretRef: name: cluster-letsencrypt-prod server: https://acme-v02.api.letsencrypt.org/directory solvers: - http01: ingress: class: traefik 三、Ingress应用ClusterIssuer #  kind: Ingress apiVersion: extensions/v1beta1 metadata: name: harbor-ingress namespace: ns-harbor labels: app: harbor chart: harbor heritage: Helm release: harbor annotations: cert-manager.io/cluster-issuer: cluster-letsencrypt-prod spec: tls: - hosts: - harbor.domian.io secretName: harbor-letsencrypt-tls rules: - host: harbor.domian.io http: paths: - path: / backend: serviceName: harbor-harbor-portal servicePort: 80 Ingress通过在annotations中添加cert-manager.</description>
    </item>
    
    <item>
      <title>Ceph集群安装</title>
      <link>https://hnbcao.vip/docs/seo/middleware/ceph-installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/seo/middleware/ceph-installation/</guid>
      <description>CephFS集群安装 #  一、集群规划 #     节点 ip os 节点说明     master1 10.73.13.61 centos7.4 mon+rgw+manger节点、ceph-deploy   master2 10.73.13.60 centos7.4 mon+rgw+manger节点   master3 10.73.13.59 centos7.4 mon+rgw+manger节点    二、安装ceph-deploy #   Install and enable the Extra Packages for Enterprise Linux (EPEL) repository:Install and enable the Extra Packages for Enterprise Linux (EPEL) repository:  sudo yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm 添加ceph仓库（阿里源，同时在所有节点进行如下操作）  cat &amp;lt;&amp;lt; EOM &amp;gt; /etc/yum.</description>
    </item>
    
    <item>
      <title>Kubernetes集群安装Traefik Ingress</title>
      <link>https://hnbcao.vip/docs/container/kubernetes/3-kubernetes-traefik-ingress/</link>
      <pubDate>Tue, 31 Dec 2019 17:21:39 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/container/kubernetes/3-kubernetes-traefik-ingress/</guid>
      <description>部署TraefikIngress #  一、创建证书 #  使用OpenSSL创建TLS证书（已有证书则跳过该选项）
 设置证书信息  cd ~ &amp;amp;&amp;amp; mkdir tls echo &amp;#34;&amp;#34;&amp;#34; [req] distinguished_name = req_distinguished_name prompt = yes [ req_distinguished_name ] countryName = Country Name (2 letter code) countryName_value = CN stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_value = Chongqing localityName = Locality Name (eg, city) localityName_value = Yubei organizationName = Organization Name (eg, company) organizationName_value = HNBCAO organizationalUnitName = Organizational Unit Name (eg, section) organizationalUnitName_value = R &amp;amp; D Department commonName = Common Name (eg, your name or your server\&amp;#39;s hostname) commonName_value = *.</description>
    </item>
    
    <item>
      <title>FTP服务器搭建</title>
      <link>https://hnbcao.vip/docs/seo/middleware/ftp-installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/seo/middleware/ftp-installation/</guid>
      <description>FTP服务搭建 #   系统： centos 7.4  一、安装vsftpd #  yum -y install vsftpd 二、配置服务 #  [root@ecs-7fd0 vsftpd]# cat /etc/vsftpd/vsftpd.conf anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 dirmessage_enable=YES xferlog_enable=YES xferlog_std_format=YES ascii_upload_enable=YES ascii_download_enable=YES chroot_local_user=YES listen=NO listen_ipv6=YES connect_from_port_20=NO #设置使用主动模式 pasv_enable=YES pasv_min_port=1024 pasv_max_port=65536 pam_service_name=vsftpd guest_enable=YES #设置使用虚拟用户的真实访问用户 guest_username=ftpuser user_config_dir=/etc/vsftpd/vsftpd_user_conf allow_writeable_chroot=YES #设置使用虚拟用户 virtual_use_local_privs=YES userlist_enable=YES userlist_deny=NO tcp_wrappers=YES 三、创建ftpuser账户 #  useradd -d /home/ftpuser -s /sbin/nologin ftpuser 三、虚拟用户 #   设置pam策略  [root@ecs-7fd0 vsftpd]# cat /etc/pam.d/vsftpd #%PAM-1.0 #session optional pam_keyinit.</description>
    </item>
    
    <item>
      <title>Kubernetes集群创建用户</title>
      <link>https://hnbcao.vip/docs/container/kubernetes/4-create-kubernetes-user/</link>
      <pubDate>Tue, 31 Dec 2019 17:27:30 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/container/kubernetes/4-create-kubernetes-user/</guid>
      <description>创建集群用户 #  一、创建用户 #  apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: admin-user annotations: rbac.authorization.kubernetes.io/autoupdate: &amp;#34;true&amp;#34; roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kube-system 二、获取Token #  获取管理员用户的Token，通过执行如下命令获取系统Token信息
kubectl describe secret admin-user --namespace=kube-system 三、导出配置 #  DASH_TOCKEN=$(kubectl get secret -n kube-system admin-user-token-4j272 -o jsonpath={.data.token}|base64 -d) kubectl config set-cluster kubernetes --server=https://172.16.0.9:8443 --kubeconfig=/root/kube-admin.conf kubectl config set-credentials admin-user --token=$DASH_TOCKEN --kubeconfig=/root/kube-admin.</description>
    </item>
    
    <item>
      <title>Fluent-bit日志插件配置说明</title>
      <link>https://hnbcao.vip/docs/seo/middleware/fluent-bit-configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/seo/middleware/fluent-bit-configuration/</guid>
      <description>Fluent-bit日志插件配置说明 #  一、概述 #  fluent-bit配置文件中，主要由输入（Input）、解析器（Parser）、过滤器（Filter）、缓存（Buffer）、路由（Routing）、输出（Output）六大模块组成，各个模块的详细说明如下：
   Interface Description(英文) Description(中文)     Input Entry point of data. Implemented through Input Plugins, this interface allows to gather or receive data. E.g: log file content, data over TCP, built-in metrics, etc. 数据的入口点。通过输入插件实现，此接口允许收集或接收数据。例如：日志文件内容，TCP上的数据，内置指标等。   Parser Parsers allow to convert unstructured data gathered from the Input interface into a structured one. Parsers are optional and depends on Input plugins.</description>
    </item>
    
    <item>
      <title>Kubernetes集群创建Image Pull Secret</title>
      <link>https://hnbcao.vip/docs/container/kubernetes/5-kubernetes-create-image-pull-secret/</link>
      <pubDate>Tue, 31 Dec 2019 17:23:44 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/container/kubernetes/5-kubernetes-create-image-pull-secret/</guid>
      <description>创建ImagePullSecret #  一、登录仓库 #  登录镜像仓库，成功之后会生成如下/root/.docker/config.json文件
{ &amp;#34;auths&amp;#34;: { &amp;#34;harbor.hnbcao.tech&amp;#34;: { &amp;#34;auth&amp;#34;: &amp;#34;YWRtaW4******lRlY2g=&amp;#34; } }, &amp;#34;HttpHeaders&amp;#34;: { &amp;#34;User-Agent&amp;#34;: &amp;#34;Docker-Client/***&amp;#34; } } 二、创建ImagePullSecret #  执行如下命令创建ImagePullSecret
kubectl create secret generic harbor-admin-secret --from-file=.dockerconfigjson=/root/.docker/config.json --type=kubernetes.io/dockerconfigjson --namespace hnbcao-mixing-ore 说明：
 harbor-admin-secret： ImagePullSecret名字 type： 指定secret类型为kubernetes.io/dockerconfigjson namespace：secret命名空间  三、添加ImagePullSecret #   Deployment  在配置项的spec.template.spec.imagePullSecrets下添加secret：harbor-admin-secret。例如，Deployment的配置如下：
kind: Deployment apiVersion: apps/v1 metadata: name: app-test spec: replicas: 1 selector: matchLabels: app.kubernetes.io/instance: app-test app.kubernetes.io/name: hnbcao template: metadata: labels: app.kubernetes.io/instance: app-test app.</description>
    </item>
    
    <item>
      <title>kubernetes集群运行问题记录</title>
      <link>https://hnbcao.vip/docs/container/kubernetes/6-kubernetes-seo/</link>
      <pubDate>Thu, 02 Jan 2020 09:17:08 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/container/kubernetes/6-kubernetes-seo/</guid>
      <description>kubernetes集群运行问题记录 #  一、集群内部容器无法解析外部DNS #    原因：由于节点名为nodex.domain.xx，集群内部容器的/etc/resolv.conf中search域会domain.xx域，容器在解析外网域名时默认会先在外网域名后添加.domain.xx进行域名解析，而外网存在域名domain.xx，且DNS解析域名为*.domain.xx，所以会将外网域名解析至*.domain.xx对应的IP地址，最终导致容器内部无法访问外网域名。
  解决办法：尽量避免集群内部节点名与外网域名冲突，可采用domain.local结尾等命名方式为节点命名。
  二、gitlab迁移之后系统异常 #    原因：集群新建gitlab仓库各组件之间的认证文件与原有gialab不一致，导致恢复数据之后部分组件之间交互异常。
  解决办法：新建gitlab之前，迁移原有gitlab中所有的secret文件。
  三、kubernetes证书相关问题 #    原因：由于没有配置etcd证书的sans，导致集群master节点故障时，etcd无法启动，集群崩溃。
  解决办法：
 查看etcd日志，发现有出现关于证书的错误信息。master节点上执行openssl x509 -text -in /etc/kubernetes/pki/etcd/server.crt -noout查看证书的sans。输出证书信息为：  Certificate: ... X509v3 extensions: ... X509v3 Subject Alternative Name: DNS:master1.segma.local, DNS:localhost, IP Address:192.168.1.202, IP Address:127.0.0.1, IP Address:0:0:0:0:0:0:0:1 ... 其中X509v3 Subject Alternative Name项中，DNS和IP地址不包括其他主节点地址，所以证书不完整，需要重新生成证书。
以下所有操作在所有主节点上执行。首先备份/etc/kubernetes/pki下所有文件  cp -r /etc/kubernetes/pki /etc/kubernetes/pki_backup 使用kubeadm生成证书，新建kubeadm config文件，填写其他master节点信息。内容如下：</description>
    </item>
    
    <item>
      <title>Kubernetes集群GPU共享解决方案</title>
      <link>https://hnbcao.vip/docs/container/kubernetes/7-kubernetes-with-aliyungpu/</link>
      <pubDate>Tue, 16 Jun 2020 14:16:38 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/container/kubernetes/7-kubernetes-with-aliyungpu/</guid>
      <description>Kubernetes集群GPU共享解决方案 #  基于阿里云的GPU共享方案 #  https://github.com/AliyunContainerService/gpushare-scheduler-extender/blob/master/docs/install.md</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hnbcao.vip/docs/example/collapsed/3rd-level/4th-level/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/example/collapsed/3rd-level/4th-level/</guid>
      <description>4th Level of Menu #  Caesorum illa tu sentit micat vestes papyriferi #  Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.
Venasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto!</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hnbcao.vip/docs/example/hidden/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/example/hidden/</guid>
      <description>This page is hidden in menu #  Quondam non pater est dignior ille Eurotas #  Latent te facies #  Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.
 Pater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor  Cum honorum Latona #  O fallor in sustinui iussorum equidem.</description>
    </item>
    
    <item>
      <title>Java学习笔记</title>
      <link>https://hnbcao.vip/docs/java/note/java/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/java/note/java/</guid>
      <description>Java学习笔记 #  容器 #   ArrayList与LinkList对比：   性能：《Java编程思想》指出，ArrayList插入移除元素较慢，ArrayList添加元素的速度比LinkList快。。LinkList插入移除元素速度优于ArrayList，且在数据量大时，ArrayList移除元素异常缓慢（按照元素顺序插入移除，若倒序插入移除则快于LinkList），其中的原因是LinkList使用双向链表存储数据，移除时只需要修改待移除元素的前后节点的next与prev位置即可，而ArrayList则涉及到数组的拷贝，倒序的情况下，ArrayList只需要将末尾元素移除即可。 建议：在涉及元素删除的List中，建议使用LinkList，其他情况可使用ArrayList。ArrayList使用在查询比较多，但是插入和删除比较少的情况，而LinkedList用在查询比较少而插入删除比较多的情况。   ArrayList、LinkList、Vector、Stack中只有Stack、Vector是线程安全的类，线程安全的List还有CopyOnWriteArrayList和Collections.synchronizedList()。Collections.synchronizedList()使用装饰模式为传入的List操作加上同步锁。
  Stack底层数据结构是Vector，Vector的所有操作都加了synchronized关键字，Vector的底层使用数组保存数据，类似与ArrayList。一般多线程状态下使用List会选择Vector。
  HashSet底层数据结构是HashMap
  LinkedHashSet底层数据结构是LinkedHashMap
  </description>
    </item>
    
    <item>
      <title>Spring Kafka参数配置详情</title>
      <link>https://hnbcao.vip/docs/java/note/spring-kafka-properties/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hnbcao.vip/docs/java/note/spring-kafka-properties/</guid>
      <description>Spring Kafka参数配置详情 #  一、全局配置 #  # 用逗号分隔的主机:端口对列表，用于建立到Kafka群集的初始连接。覆盖全局连接设置属性 spring.kafka.bootstrap-servers # 在发出请求时传递给服务器的ID。用于服务器端日志记录 spring.kafka.client-id，默认无 # 用于配置客户端的其他属性，生产者和消费者共有的属性 spring.kafka.properties.* # 消息发送的默认主题，默认无 spring.kafka.template.default-topic 二、生产者 #  Spring Boot中，Kafka 生产者相关配置(所有配置前缀为spring.kafka.producer.)：
# 生产者要求Leader在考虑请求完成之前收到的确认数 spring.kafka.producer.acks # 默认批量大小。较小的批处理大小将使批处理不太常见，并可能降低吞吐量（批处理大小为零将完全禁用批处理） spring.kafka.producer.batch-size spring.kafka.producer.bootstrap-servers # 生产者可用于缓冲等待发送到服务器的记录的总内存大小。 spring.kafka.producer.buffer-memory # 在发出请求时传递给服务器的ID。用于服务器端日志记录。 spring.kafka.producer.client-id # 生产者生成的所有数据的压缩类型 spring.kafka.producer.compression-type # 键的序列化程序类 spring.kafka.producer.key-serializer spring.kafka.producer.properties.* # 大于零时，启用失败发送的重试次数 spring.kafka.producer.retries spring.kafka.producer.ssl.key-password spring.kafka.producer.ssl.key-store-location spring.kafka.producer.ssl.key-store-password spring.kafka.producer.ssl.key-store-type spring.kafka.producer.ssl.protocol spring.kafka.producer.ssl.trust-store-location spring.kafka.producer.ssl.trust-store-password spring.kafka.producer.ssl.trust-store-type # 非空时，启用对生产者的事务支持 spring.kafka.producer.transaction-id-prefix spring.kafka.producer.value-serializer 三、消费者 #  Spring Boot中，Kafka 消费者相关配置(所有配置前缀为spring.kafka.consumer.)：
# 如果“enable.auto.commit”设置为true，设置消费者偏移自动提交到Kafka的频率，默认值无，单位毫秒(ms) spring.kafka.consumer.auto-commit-interval # 当Kafka中没有初始偏移或服务器上不再存在当前偏移时策略设置，默认值无，latest/earliest/none三个值设置 # earliest 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费 # latest 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据 # none topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常 spring.</description>
    </item>
    
  </channel>
</rss>
